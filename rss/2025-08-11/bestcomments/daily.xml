<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ns0="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Hacker News: Best Comments</title><link>https://news.ycombinator.com/bestcomments</link><description>Hacker News RSS</description><docs>https://hnrss.org/</docs><generator>hnrss v2.1.1</generator><lastBuildDate>Sun, 10 Aug 2025 23:49:10 +0000</lastBuildDate><ns0:link href="https://hnrss.org/bestcomments" rel="self" type="application/rss+xml" /><item><title>New comment by Uehreka in "GPT-5: Overdue, overhyped and underwhelming. And that's not the worst of it"</title><description>
&lt;p&gt;This is a genre of article I find particularly annoying. Instead of writing an essay on why he personally thinks GPT-5 is bad based on his own analysis, the author just gathers up a bunch of social media reactions and tells us about them, characterizing every criticism as “devastating” or a “slam”, and then hopes that the combined weight of these overtorqued summaries will convince us to see things his way.&lt;p&gt;It’s both too slanted to be journalism, but not original enough to be analysis.&lt;/p&gt;
</description><pubDate>Sun, 10 Aug 2025 00:32:06 +0000</pubDate><link>https://news.ycombinator.com/item?id=44851706</link><dc:creator>Uehreka</dc:creator><comments>https://news.ycombinator.com/item?id=44851706</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44851706</guid></item><item><title>New comment by ryandrake in "Show HN: The current sky at your approximate location, as a CSS gradient"</title><description>
&lt;p&gt;Awesome. I remember much earlier in my career I was working on a 3D turn-by-turn navigation software, and one of my tasks was to draw the sky in the background. The more senior guy on the team said, just draw a blue rectangle during the day and a dark gray one at night and call it job done. Of course, I had to do it the hard way, so I looked up the relevant literature on sky rendering based on the environment, latitude, longitude, time of day and so on, which at the time was Preetham[1] ("A Practical Analytic Model for Daylight"), and built a fully realistic sky model for the software. I even added prominent stars based on a hard-coded ephemeris table. It was quite fast, too.&lt;p&gt;Well, the higher ups of course hated it, they were confused as to why the horizon would get hazy, yellowish, and so on. "Our competitors' skies are blue!" They didn't like "Use your eyes and look outside" as an answer.&lt;p&gt;Eventually, I was told to scrap it and just draw a blue rectangle :(&lt;p&gt;All that to say, nice job on the site!&lt;p&gt;1: &lt;a href="https://courses.cs.duke.edu/cps124/fall01/resources/p91-preetham.pdf" rel="nofollow"&gt;https://courses.cs.duke.edu/cps124/fall01/resources/p91-pree...&lt;/a&gt;&lt;/p&gt;
</description><pubDate>Sat, 09 Aug 2025 14:07:03 +0000</pubDate><link>https://news.ycombinator.com/item?id=44846565</link><dc:creator>ryandrake</dc:creator><comments>https://news.ycombinator.com/item?id=44846565</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44846565</guid></item><item><title>New comment by canyon289 in "Ask HN: How can ChatGPT serve 700M users when I can't run one GPT-4 locally?"</title><description>
&lt;p&gt;I work at Google on these systems everyday (caveat this is my own words not my employers)). So I simultaneously can tell you that its smart people really thinking about every facet of the problem, and I can't tell you much more than that.&lt;p&gt;However I can share this written by my colleagues! You'll find great explanations about accelerator architectures and the considerations made to make things fast.&lt;p&gt;&lt;a href="https://jax-ml.github.io/scaling-book/" rel="nofollow"&gt;https://jax-ml.github.io/scaling-book/&lt;/a&gt;&lt;p&gt;In particular your questions are around inference which is the focus of this chapter
&lt;a href="https://jax-ml.github.io/scaling-book/inference/" rel="nofollow"&gt;https://jax-ml.github.io/scaling-book/inference/&lt;/a&gt;&lt;p&gt;Edit:
Another great resource to look at is the unsloth guides. These folks are incredibly good at getting deep into various models and finding optimizations, and they're very good at writing it up. Here's the Gemma 3n guide, and you'll find others as well.&lt;p&gt;&lt;a href="https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune"&gt;https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-...&lt;/a&gt;&lt;/p&gt;
</description><pubDate>Fri, 08 Aug 2025 19:47:42 +0000</pubDate><link>https://news.ycombinator.com/item?id=44840935</link><dc:creator>canyon289</dc:creator><comments>https://news.ycombinator.com/item?id=44840935</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44840935</guid></item><item><title>New comment by beeflet in "GPT-5"</title><description>
&lt;p&gt;Perhaps it is not possible to simulate higher-level intelligence using a stochastic model for predicting text.&lt;p&gt;I am not an AI researcher, but I have friends who do work in the field, and they are not worried about LLM-based AGI because of the diminishing returns on results vs amount of training data required. Maybe this is the bottleneck.&lt;p&gt;Human intelligence is markedly different from LLMs: it requires far fewer examples to train on, and generalizes way better. Whereas LLMs tend to regurgitate solutions to solved problems, where the solutions tend to be well-published in training data.&lt;p&gt;That being said, AGI is not a necessary requirement for AI to be totally world-changing. There are possibly applications of existing AI/ML/SL technology which could be more impactful than general intelligence. Search is one example where the ability to regurgitate knowledge from many domains is desirable&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 18:17:24 +0000</pubDate><link>https://news.ycombinator.com/item?id=44828331</link><dc:creator>beeflet</dc:creator><comments>https://news.ycombinator.com/item?id=44828331</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44828331</guid></item><item><title>New comment by highfrequency in "GPT-5"</title><description>
&lt;p&gt;It is frequently suggested that once one of the AI companies reaches an AGI threshold, they will take off ahead of the rest. It's interesting to note that at least so far, the trend has been the opposite: as time goes on and the models get better, the performance of the different company's gets clustered closer together. Right now GPT-5, Claude Opus, Grok 4, Gemini 2.5 Pro all seem quite good across the board (ie they can all basically solve moderately challenging math and coding problems).&lt;p&gt;As a user, it feels like the race has never been as close as it is now. Perhaps dumb to extrapolate, but it makes me lean more skeptical about the hard take-off / winner-take-all mental model that has been pushed.&lt;p&gt;Would be curious to hear the take of a researcher at one of these firms - do you expect the AI offerings across competitors to become more competitive and clustered over the next few years, or less so?&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 18:05:12 +0000</pubDate><link>https://news.ycombinator.com/item?id=44828137</link><dc:creator>highfrequency</dc:creator><comments>https://news.ycombinator.com/item?id=44828137</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44828137</guid></item><item><title>New comment by surround in "GPT-5"</title><description>
&lt;p&gt;GPT-5 knowledge cutoff: Sep 30, 2024 (10 months before release).&lt;p&gt;Compare that to&lt;p&gt;Gemini 2.5 Pro knowledge cutoff: Jan 2025 (3 months before release)&lt;p&gt;Claude Opus 4.1: knowledge cutoff: Mar 2025 (4 months before release)&lt;p&gt;&lt;a href="https://platform.openai.com/docs/models/compare" rel="nofollow"&gt;https://platform.openai.com/docs/models/compare&lt;/a&gt;&lt;p&gt;&lt;a href="https://deepmind.google/models/gemini/pro/" rel="nofollow"&gt;https://deepmind.google/models/gemini/pro/&lt;/a&gt;&lt;p&gt;&lt;a href="https://docs.anthropic.com/en/docs/about-claude/models/overview" rel="nofollow"&gt;https://docs.anthropic.com/en/docs/about-claude/models/overv...&lt;/a&gt;&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 17:53:29 +0000</pubDate><link>https://news.ycombinator.com/item?id=44827929</link><dc:creator>surround</dc:creator><comments>https://news.ycombinator.com/item?id=44827929</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44827929</guid></item><item><title>New comment by peterdsharpe in "GPT-5"</title><description>
&lt;p&gt;Yes, it is completely wrong. If this were a valid explanation, flat-plate airfoils could not generate lift. (They can.)&lt;p&gt;Source: PhD on aircraft design&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 17:43:03 +0000</pubDate><link>https://news.ycombinator.com/item?id=44827735</link><dc:creator>peterdsharpe</dc:creator><comments>https://news.ycombinator.com/item?id=44827735</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44827735</guid></item><item><title>New comment by pram in "GPT-5"</title><description>
&lt;p&gt;We’re at the audiophile stage of LLMs where people are talking about the improved soundstage, tonality, reduced sibilance etc&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 17:19:26 +0000</pubDate><link>https://news.ycombinator.com/item?id=44827352</link><dc:creator>pram</dc:creator><comments>https://news.ycombinator.com/item?id=44827352</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44827352</guid></item><item><title>New comment by mtlynch in "GPT-5"</title><description>
&lt;p&gt;What's going on with their SWE bench graph?[0]&lt;p&gt;GPT-5 non-thinking is labeled 52.8% accuracy, but o3 is shown as a much shorter bar, yet it's labeled 69.1%. And 4o is an identical bar to o3, but it's labeled 30.8%...&lt;p&gt;[0] &lt;a href="https://i.postimg.cc/DzkZZLry/y-axis.png" rel="nofollow"&gt;https://i.postimg.cc/DzkZZLry/y-axis.png&lt;/a&gt;&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 17:10:12 +0000</pubDate><link>https://news.ycombinator.com/item?id=44827179</link><dc:creator>mtlynch</dc:creator><comments>https://news.ycombinator.com/item?id=44827179</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44827179</guid></item><item><title>New comment by t_mann in "Emailing a one-time code is worse than passwords"</title><description>
&lt;p&gt;The problems of Passkeys are more nuanced than just losing access when a device is lost (which actually doesn't need to happen depending on your setup). The biggest problem are attestations, which let services block users who use tools that give them more freedom. Passkeys, or more generally challenge-response protocols, could easily have been an amazing replacement for passwords and a win-win for everyone. Unfortunately, the reality of how they've been designed is that they will mainly serve to further cement the primacy of BigTech and take away user freedom.&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 05:58:02 +0000</pubDate><link>https://news.ycombinator.com/item?id=44821089</link><dc:creator>t_mann</dc:creator><comments>https://news.ycombinator.com/item?id=44821089</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44821089</guid></item><item><title>New comment by DecoPerson in "Emailing a one-time code is worse than passwords"</title><description>
&lt;p&gt;The attack pattern is:&lt;p&gt;1) User goes to BAD website and signs up.&lt;p&gt;2) BAD website says “We’ve sent you an email, please enter the 6-digit code! The email will come from GOOD, as they are our sign-in partner.”&lt;p&gt;3) BAD’s bots start a “Sign in with email one-time code” flow on the GOOD website using the user’s email.&lt;p&gt;4) GOOD sends a one-time login code email to the user’s email address.&lt;p&gt;5) The user is very likely to trust this email, because it’s from GOOD, and why would GOOD send it if it’s not a proper login?&lt;p&gt;6) User enters code into BAD’s website.&lt;p&gt;7) BAD uses code to login to GOOD’s website as the user. BAD now has full access to the user’s GOOD account.&lt;p&gt;This is why “email me a one-time code” is one of the worst authentication flows for phishing. It’s just so hard to stop users from making this mistake.&lt;p&gt;“Click a link in the email” is a tiny bit better because it takes the user straight to the GOOD website, and passing that link to BAD is more tedious and therefore more suspicious. However, if some popular email service suddenly decides your login emails or the login link within should be blocked, then suddenly many of your users cannot login.&lt;p&gt;Passkeys is the way to go. Password manager support for passkeys is getting really good. And I assure you, all passkeys being lost when a user loses their phone is far, far better than what’s been happening with passwords. I’d rather granny needs to visit the bank to get access to her account again, than someone phishes her and steals all her money.&lt;/p&gt;
</description><pubDate>Thu, 07 Aug 2025 03:37:03 +0000</pubDate><link>https://news.ycombinator.com/item?id=44820331</link><dc:creator>DecoPerson</dc:creator><comments>https://news.ycombinator.com/item?id=44820331</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44820331</guid></item><item><title>New comment by duskwuff in "We'd be better off with 9-bit bytes"</title><description>
&lt;p&gt;Non-power-of-2 sizes are awkward from a hardware perspective. A lot of designs for e.g. optimized multipliers depend on the operands being divisible into halves; that doesn't work with units of 9 bits. It's also nice to be able to describe a bit position using a fixed number of bits (e.g. 0-7 in 3 bits, 0-31 in 5 bits, 0-63 in 6 bits), e.g. to represent a number of bitwise shift operations, or to select a bit from a byte; this also falls apart with 9, where you'd have to use four bits and have a bunch of invalid values.&lt;/p&gt;
</description><pubDate>Wed, 06 Aug 2025 21:27:01 +0000</pubDate><link>https://news.ycombinator.com/item?id=44818052</link><dc:creator>duskwuff</dc:creator><comments>https://news.ycombinator.com/item?id=44818052</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44818052</guid></item><item><title>New comment by hyperpape in "We shouldn't have needed lockfiles"</title><description>
&lt;p&gt;&gt; But if you want an existence proof: Maven. The Java library ecosystem has been going strong for 20 years, and during that time not once have we needed a lockfile. And we are pulling hundreds of libraries just to log two lines of text, so it is actively used at scale.&lt;p&gt;Maven, by default, does not check your transitive dependencies for version conflicts. To do that, you need a frustrating plugin that produces much worse error messages than NPM does: &lt;a href="https://ourcraft.wordpress.com/2016/08/22/how-to-read-maven-enforcer-plugins-requireupperbounddeps-rule-failure-report/" rel="nofollow"&gt;https://ourcraft.wordpress.com/2016/08/22/how-to-read-maven-...&lt;/a&gt;.&lt;p&gt;How does Maven resolve dependencies when two libraries pull in different versions? It does something insane. &lt;a href="https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html" rel="nofollow"&gt;https://maven.apache.org/guides/introduction/introduction-to...&lt;/a&gt;.&lt;p&gt;Do not pretend, for even half a second, that dependency resolution is not hell in maven (though I do like that packages are namespaced by creators, npm shoulda stolen that).&lt;/p&gt;
</description><pubDate>Wed, 06 Aug 2025 15:59:25 +0000</pubDate><link>https://news.ycombinator.com/item?id=44813767</link><dc:creator>hyperpape</dc:creator><comments>https://news.ycombinator.com/item?id=44813767</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44813767</guid></item><item><title>New comment by pentamassiv in "I gave the AI arms and legs then it rejected me"</title><description>
&lt;p&gt;Hey, I'm the author of the blog post. Thank you for submitting this. If you have any questions feel free to ask and please let me know how the writing was. It's one of my first posts so I'd like to improve&lt;/p&gt;
</description><pubDate>Wed, 06 Aug 2025 07:50:27 +0000</pubDate><link>https://news.ycombinator.com/item?id=44808997</link><dc:creator>pentamassiv</dc:creator><comments>https://news.ycombinator.com/item?id=44808997</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44808997</guid></item><item><title>New comment by pentamassiv in "Ask HN: Have you ever regretted open-sourcing something?"</title><description>
&lt;p&gt;I am the maintainer of a library to simulate keyboard and mouse input. I didn't start the project but took over the maintenance and have since rewritten pretty much all of the code. I recently found out that Anthropic is shipping it in Claude Desktop for some unreleased feature which is probably like "Computer Use". I noticed they had an open position in exactly the team responsible for the implementation and applied. A few months later I received a rejection. The letter said that the team doesn't have the time to review any more candidates. The code is under MIT so everything is perfectly fine. It is great that a company like Anthropic is using my code, but it would have been nice to benefit from it. I wrote a slightly longer blog post about the topic here:&lt;p&gt;&lt;a href="https://grell.dev/blog/ai_rejection" rel="nofollow"&gt;https://grell.dev/blog/ai_rejection&lt;/a&gt;&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 22:59:27 +0000</pubDate><link>https://news.ycombinator.com/item?id=44805556</link><dc:creator>pentamassiv</dc:creator><comments>https://news.ycombinator.com/item?id=44805556</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44805556</guid></item><item><title>New comment by erulabs in "Ask HN: Have you ever regretted open-sourcing something?"</title><description>
&lt;p&gt;When I was ~14 I open sourced a script to autoconfigure X11's xrandr. It was pretty lousy, had several bugs. I mentioned it on a KDE mailing list and a KDE core contributor told me it was embarrassing code and to kill myself. I took it pretty hard and didn't contribute to KDE or X11 ever again, probably took me about a year to build up the desire to code again.&lt;p&gt;Everything else I've open-sourced has gone pretty well, comparatively.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 22:37:38 +0000</pubDate><link>https://news.ycombinator.com/item?id=44805363</link><dc:creator>erulabs</dc:creator><comments>https://news.ycombinator.com/item?id=44805363</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44805363</guid></item><item><title>New comment by cco in "Open models by OpenAI"</title><description>
&lt;p&gt;The lede is being missed imo.&lt;p&gt;gpt-oss:20b is a top ten model (on MMLU (right behind Gemini-2.5-Pro) and I just ran it locally on my Macbook Air M3 from last year.&lt;p&gt;I've been experimenting with a lot of local models, both on my laptop and on my phone (Pixel 9 Pro), and I figured we'd be here in a year or two.&lt;p&gt;But no, we're here today. A basically frontier model, running for the cost of electricity (free with a rounding error) on my laptop. No $200/month subscription, no lakes being drained, etc.&lt;p&gt;I'm blown away.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 21:13:25 +0000</pubDate><link>https://news.ycombinator.com/item?id=44804397</link><dc:creator>cco</dc:creator><comments>https://news.ycombinator.com/item?id=44804397</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44804397</guid></item><item><title>New comment by kridsdale3 in "Claude Opus 4.1"</title><description>
&lt;p&gt;Given the Gregorian Calendar and the planet's path through its orbit, August is just getting started.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 18:26:27 +0000</pubDate><link>https://news.ycombinator.com/item?id=44802150</link><dc:creator>kridsdale3</dc:creator><comments>https://news.ycombinator.com/item?id=44802150</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44802150</guid></item><item><title>New comment by foundry27 in "Open models by OpenAI"</title><description>
&lt;p&gt;Model cards, for the people interested in the guts: &lt;a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf" rel="nofollow"&gt;https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7...&lt;/a&gt;&lt;p&gt;In my mind, I’m comparing the model architecture they describe to what the leading open-weights models (Deepseek, Qwen, GLM, Kimi) have been doing. Honestly, it just seems “ok” at a technical level:&lt;p&gt;- both models use standard Grouped-Query Attention (64 query heads, 8 KV heads). The card talks about how they’ve used an older optimization from GPT3, which is alternating between banded window (sparse, 128 tokens) and fully dense attention patterns. It uses RoPE extended with YaRN (for a 131K context window). So they haven’t been taking advantage of the special-sauce Multi-head Latent Attention from Deepseek, or any of the other similar improvements over GQA.&lt;p&gt;- both models are standard MoE transformers. The 120B model (116.8B total, 5.1B active) uses 128 experts with Top-4 routing. They’re using some kind of Gated SwiGLU activation, which the card talks about as being "unconventional" because of to clamping and whatever residual connections that implies. Again, not using any of Deepseek’s “shared experts” (for general patterns) + “routed experts” (for specialization) architectural improvements, Qwen’s load-balancing strategies, etc.&lt;p&gt;- the most interesting thing IMO is probably their quantization solution. They did something to quantize &gt;90% of the model parameters to the MXFP4 format (4.25 bits/parameter) to let the 120B model to fit on a single 80GB GPU, which is pretty cool. But we’ve also got Unsloth with their famous 1.58bit quants :)&lt;p&gt;All this to say, it seems like even though the training they did for their agentic behavior and reasoning is undoubtedly very good, they’re keeping their actual technical advancements “in their pocket”.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 17:57:40 +0000</pubDate><link>https://news.ycombinator.com/item?id=44801714</link><dc:creator>foundry27</dc:creator><comments>https://news.ycombinator.com/item?id=44801714</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44801714</guid></item><item><title>New comment by pitpatagain in "Ozempic shows anti-aging effects in trial"</title><description>
&lt;p&gt;This is specifically a study on people with HIV-associated lipohypertrophy, which is associated with accelerated aging. Not clear what this would mean for people generally.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 17:39:12 +0000</pubDate><link>https://news.ycombinator.com/item?id=44801396</link><dc:creator>pitpatagain</dc:creator><comments>https://news.ycombinator.com/item?id=44801396</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44801396</guid></item><item><title>New comment by qsort in "Claude Opus 4.1"</title><description>
&lt;p&gt;All three major labs released something within hours of each other. This anime arc is insane.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 16:42:05 +0000</pubDate><link>https://news.ycombinator.com/item?id=44800421</link><dc:creator>qsort</dc:creator><comments>https://news.ycombinator.com/item?id=44800421</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44800421</guid></item><item><title>New comment by simonw in "Things that helped me get out of the AI 10x engineer imposter syndrome"</title><description>
&lt;p&gt;I found myself agreeing with quite a lot of this article.&lt;p&gt;I'm a pretty huge proponent for AI-assisted development, but I've never found those 10x claims convincing. I've estimated that LLMs make me 2-5x more productive on the parts of my job which involve typing code into a computer, which is itself a small portion of that I do as a software engineer.&lt;p&gt;That's not too far from this article's assumptions. From the article:&lt;p&gt;&gt; I wouldn't be surprised to learn AI helps many engineers do certain tasks 20-50% faster, but the nature of software bottlenecks mean this doesn't translate to a 20% productivity increase and certainly not a 10x increase.&lt;p&gt;I think that's an under-estimation - I suspect engineers that really know how to use this stuff effectively will get more than a 0.2x increase - but I do think all of the &lt;i&gt;other stuff&lt;/i&gt; involved in building software makes the 10x thing unrealistic in most cases.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 14:41:45 +0000</pubDate><link>https://news.ycombinator.com/item?id=44798605</link><dc:creator>simonw</dc:creator><comments>https://news.ycombinator.com/item?id=44798605</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44798605</guid></item><item><title>New comment by modeless in "Genie 3: A new frontier for world models"</title><description>
&lt;p&gt;Consistency over multiple minutes &lt;i&gt;and&lt;/i&gt; it runs in real time at 720p? I did not expect world models to be this good yet.&lt;p&gt;&gt; Genie 3’s consistency is an emergent capability&lt;p&gt;So this just happened from scaling the model, rather than being a consequence of deliberate architecture changes?&lt;p&gt;Edit: here is some commentary on limitations from someone who tried it: &lt;a href="https://x.com/tejasdkulkarni/status/1952737669894574264" rel="nofollow"&gt;https://x.com/tejasdkulkarni/status/1952737669894574264&lt;/a&gt;&lt;p&gt;&gt; - Physics is still hard and there are obvious failure cases when I tried the classical intuitive physics experiments from psychology (tower of blocks).&lt;p&gt;&gt; - Social and multi-agent interactions are tricky to handle. 1vs1 combat games do not work&lt;p&gt;&gt; - Long instruction following and simple combinatorial game logic fails (e.g. collect some points / keys etc, go to the door, unlock and so on)&lt;p&gt;&gt; - Action space is limited&lt;p&gt;&gt; - It is far from being a real game engines and has a long way to go but this is a clear glimpse into the future.&lt;p&gt;Even with these limitations, this is still bonkers. It suggests to me that world models may have a bigger part to play in robotics and real world AI than I realized. Future robots may learn in their dreams...&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 14:39:25 +0000</pubDate><link>https://news.ycombinator.com/item?id=44798564</link><dc:creator>modeless</dc:creator><comments>https://news.ycombinator.com/item?id=44798564</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44798564</guid></item><item><title>New comment by kaffekaka in "Ask HN: What trick of the trade took you too long to learn?"</title><description>
&lt;p&gt;Not a trick of the programming trade, but: life will not be clean, smooth and according to plan. Learn how to deal with things getting messy and derailed, and to accept that you "lost your streak" or whatever. Tomorrow is a new day, it is always ok to start over.&lt;p&gt;Do optimize for the long term, but also realize you could be dead by next morning.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 06:25:40 +0000</pubDate><link>https://news.ycombinator.com/item?id=44794886</link><dc:creator>kaffekaka</dc:creator><comments>https://news.ycombinator.com/item?id=44794886</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44794886</guid></item><item><title>New comment by backprop1989 in "Tell HN: Anthropic expires paid credits after a year"</title><description>
&lt;p&gt;Accounting rules. If the credits last indefinitely, any unused credits cannot be counted as revenue. Ran into this at my last company when we signed a big contract and gave them hundreds of thousands of dollars in non-expiring credits. Our accountant went nuts when we told him.&lt;/p&gt;
</description><pubDate>Tue, 05 Aug 2025 02:51:09 +0000</pubDate><link>https://news.ycombinator.com/item?id=44793827</link><dc:creator>backprop1989</dc:creator><comments>https://news.ycombinator.com/item?id=44793827</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44793827</guid></item><item><title>New comment by seydor in "Perplexity is using stealth, undeclared crawlers to evade no-crawl directives"</title><description>
&lt;p&gt;&gt; it is built on trust.&lt;p&gt;This is funny coming from Cloudflare, the company that blocks most of the internet from being fetched with antispam checks even for a single web request. The internet we knew was open and not trusted , but thanks to companies like Cloudflare, now even the most benign , well meaning attempt to GET a website is met with a brick wall. The bots of Big Tech, namely Google, Meta and Apple  are of course exempt from this by pretty much every website and by cloudflare. But try being anyone other than them , no luck. Cloudflare is the biggest enabler of this monopolistic behavior&lt;p&gt;That said, why does perplexity even need to crawl websites? I thought they used 3rd party LLMs. And those LLMs didn't ask anyones permission to crawl the entire 'net.&lt;p&gt;Also the "perplexity bots" arent crawling websites, they fetch URLs that the users explicitly asked. This shouldnt count as something that needs robots.txt access. It's not a robot randomly crawling, it's the user asking for a specific page and basically a shortcut for copy/pasting the content&lt;/p&gt;
</description><pubDate>Mon, 04 Aug 2025 16:10:16 +0000</pubDate><link>https://news.ycombinator.com/item?id=44787815</link><dc:creator>seydor</dc:creator><comments>https://news.ycombinator.com/item?id=44787815</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44787815</guid></item><item><title>New comment by rob74 in "Mastercard deflects blame for NSFW games being taken down"</title><description>
&lt;p&gt;So... Mastercard's statement is very clear:&lt;p&gt;&gt; &lt;i&gt;Put simply, we allow all lawful purchases on our network.&lt;/i&gt;&lt;p&gt;But their "Rule 5.12.7" is... not so clear:&lt;p&gt;&gt; &lt;i&gt;A Merchant must not submit to its Acquirer, and a Customer must not submit to the Interchange System, any Transaction that is illegal, or in the sole discretion of the Corporation, may damage the goodwill of the Corporation or reflect negatively on the Marks.&lt;/i&gt;&lt;p&gt;Well, which one is it now? All lawful purchases (pretty clear-cut) or only lawful purchases that will not "reflect negatively" on Mastercard in Mastercard's opinion (vague as hell)?&lt;/p&gt;
</description><pubDate>Mon, 04 Aug 2025 15:15:04 +0000</pubDate><link>https://news.ycombinator.com/item?id=44787005</link><dc:creator>rob74</dc:creator><comments>https://news.ycombinator.com/item?id=44787005</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44787005</guid></item><item><title>New comment by fxtentacle in "Perplexity is using stealth, undeclared crawlers to evade no-crawl directives"</title><description>
&lt;p&gt;I find this problem quite difficult to solve:&lt;p&gt;1. If I as a human request a website, then I should be shown the content. Everyone agrees.&lt;p&gt;2. If I as the human request the software on my computer to modify the content before displaying it, for example by installing an ad-blocker into my user agent, then that's my choice and the website should not be notified about it. Most users agree, some websites try to nag you into modifying the software you run locally.&lt;p&gt;3. If I now go one step further and use an LLM to summarize content because the authentic presentation is so riddled with ads, JavaScript, and pop-ups, that the content becomes borderline unusable, then why would the LLM accessing the website on my behalf be in a different legal category as my Firefox web browser accessing the website on my behalf?&lt;/p&gt;
</description><pubDate>Mon, 04 Aug 2025 14:12:12 +0000</pubDate><link>https://news.ycombinator.com/item?id=44786039</link><dc:creator>fxtentacle</dc:creator><comments>https://news.ycombinator.com/item?id=44786039</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44786039</guid></item><item><title>New comment by Balgair in "Job-seekers are dodging AI interviewers"</title><description>
&lt;p&gt;I did one of these once. &lt;i&gt;Once&lt;/i&gt;.&lt;p&gt;I felt so bad afterwards that I swore them off forever.&lt;p&gt;It's not like the 'interview' was terrible or anything. I knew it was AI from the start.&lt;p&gt;It was just that when I got done with it, I realized that I had talked at a computer for ~45 minutes. And, yet again, I was going to be ghosted by the company (I was), and that I was never going to get those 45 minutes back. That was time I could have used to apply for another job, or cook, or sleep, or exercise, or spend time with family. But no, like an idiot, I talked at a bot for that time for literally no reason.&lt;p&gt;Like, sure &lt;i&gt;maaaaybe&lt;/i&gt; the company is going to use it as a screen for 'real' people. But the odds that it's not just another hoop they have for you to jump through are nil. If they send an AI 'interview' at you, that's the exact same as an email requesting yet more portfolio submissions. Pointless.&lt;/p&gt;
</description><pubDate>Mon, 04 Aug 2025 13:40:36 +0000</pubDate><link>https://news.ycombinator.com/item?id=44785645</link><dc:creator>Balgair</dc:creator><comments>https://news.ycombinator.com/item?id=44785645</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44785645</guid></item><item><title>New comment by cedws in "Mastercard deflects blame for NSFW games being taken down"</title><description>
&lt;p&gt;I'm glad the Mastercard-Visa duopoly is finally getting some attention, these companies shouldn't be allowed to exercise the financial control they do. Payment infrastructure is not a free market - you can't just choose to pay via some other processor if they turn you down, they ARE the processors. Therefore, they should be under intense scrutiny when they refuse.&lt;/p&gt;
</description><pubDate>Mon, 04 Aug 2025 11:30:25 +0000</pubDate><link>https://news.ycombinator.com/item?id=44784378</link><dc:creator>cedws</dc:creator><comments>https://news.ycombinator.com/item?id=44784378</comments><guid isPermaLink="false">https://news.ycombinator.com/item?id=44784378</guid></item></channel></rss>